{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a prototyping dataset with individual cells\n",
    "\n",
    "My full solution is described here: https://www.kaggle.com/c/hpa-single-cell-image-classification/discussion/221550\n",
    "\n",
    "What I need as an input to the classification model are images of individual cells. For experimentation I don't need all the images, instead I create a sample from the train set. The additional benefit is that my sample is more balanced than train. I use RGB channels only, which has proven to work well in the previous HPA challenge. I save the extracted cells as RGB jpg images so that I can feed them easily into my classifier.\n",
    "\n",
    "Acknowledgements - this uses the dataset and some code by @its7171 (please upvote!):\n",
    "- https://www.kaggle.com/its7171/hpa-mask\n",
    "- https://www.kaggle.com/its7171/mmdetection-for-segmentation-training/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from multiprocessing import Pool\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = Path('../input/hpa-single-cell-image-classification')\n",
    "df = pd.read_csv(path/'train.csv')\n",
    "cell_dir = '../input/hpa-mask/train/hpa_cell_mask/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ROOT = '../input/hpa-single-cell-image-classification/'\n",
    "train_or_test = 'train'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = [str(i) for i in range(19)]\n",
    "for x in labels: df[x] = df['Label'].apply(lambda r: int(x in r.split('|')))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs_0 = df[df['Label'] == '0'].sample(n=300, random_state=42).reset_index(drop=True)\n",
    "dfs_1 = df[df['1'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_1u = df[df['Label'] == '1'].sample(n=221, random_state=42).reset_index(drop=True)\n",
    "dfs_2 = df[df['Label'] == '2'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_3 = df[df['Label'] == '3'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_4 = df[df['Label'] == '4'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_5 = df[df['Label'] == '5'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_6 = df[df['6'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_7 = df[df['Label'] == '7'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_8 = df[df['Label'] == '8'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_9 = df[df['9'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_9u = df[df['Label'] == '9'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_10 = df[df['10'] == 1].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_10u = df[df['Label'] == '10'].sample(n=200, random_state=42).reset_index(drop=True)\n",
    "dfs_11 = df[df['11'] == 1].reset_index(drop=True)\n",
    "dfs_12 = df[df['Label'] == '12'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_13 = df[df['Label'] == '13'].sample(n=400, random_state=42).reset_index(drop=True)\n",
    "dfs_14 = df[df['Label'] == '14'].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_15 = df[df['15'] == 1].reset_index(drop=True)\n",
    "dfs_16 = df[df['Label'] == '16'].sample(n=350, random_state=42).reset_index(drop=True)\n",
    "dfs_17 = df[df['17'] == 1].sample(n=500, random_state=42).reset_index(drop=True)\n",
    "dfs_18 = df[df['18'] == 1].reset_index(drop=True)\n",
    "dfs_ = [dfs_0, dfs_1, dfs_1u, dfs_2, dfs_3, dfs_4, dfs_5, dfs_6, dfs_7, dfs_8, dfs_9, dfs_9u, dfs_10, dfs_10u,\n",
    "        dfs_11, dfs_12, dfs_13, dfs_14, dfs_15, dfs_16, dfs_17, dfs_18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = pd.concat(dfs_, ignore_index=True)\n",
    "dfs.drop_duplicates(inplace=True, ignore_index=True)\n",
    "len(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_counts = {}\n",
    "for lbl in labels:\n",
    "    unique_counts[lbl] = len(dfs[dfs.Label == lbl])\n",
    "\n",
    "full_counts = {}\n",
    "for lbl in labels:\n",
    "    count = 0\n",
    "    for row_label in dfs['Label']:\n",
    "        if lbl in row_label.split('|'): count += 1\n",
    "    full_counts[lbl] = count\n",
    "    \n",
    "counts = list(zip(full_counts.keys(), full_counts.values(), unique_counts.values()))\n",
    "counts = np.array(sorted(counts, key=lambda x:-x[1]))\n",
    "counts = pd.DataFrame(counts, columns=['label', 'full_count', 'unique_count'])\n",
    "counts.set_index('label').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_cropped_cell(img, msk):\n",
    "    bmask = msk.astype(int)[...,None]\n",
    "    masked_img = img * bmask\n",
    "    true_points = np.argwhere(bmask)\n",
    "    top_left = true_points.min(axis=0)\n",
    "    bottom_right = true_points.max(axis=0)\n",
    "    cropped_arr = masked_img[top_left[0]:bottom_right[0]+1,top_left[1]:bottom_right[1]+1]\n",
    "    return cropped_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_stats(cropped_cell):\n",
    "    x = (cropped_cell/255.0).reshape(-1,3).mean(0)\n",
    "    x2 = ((cropped_cell/255.0)**2).reshape(-1,3).mean(0)\n",
    "    return x, x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_img(image_id, color, train_or_test='train', image_size=None):\n",
    "    filename = f'{ROOT}/{train_or_test}/{image_id}_{color}.png'\n",
    "    assert os.path.exists(filename), f'not found {filename}'\n",
    "    img = cv2.imread(filename, cv2.IMREAD_UNCHANGED)\n",
    "    if image_size is not None:\n",
    "        img = cv2.resize(img, (image_size, image_size))\n",
    "    if img.max() > 255:\n",
    "        img_max = img.max()\n",
    "        img = (img/255).astype('uint8')\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def resize_and_padding(img_ar, target_size=512):\n",
    "    h, w, _ = img_ar.shape\n",
    "    if h > w:\n",
    "        rs_img = cv2.resize(img_ar, (int(w*(target_size/h)), target_size)) \n",
    "    else:\n",
    "        rs_img = cv2.resize(img_ar, (target_size, int(h*(target_size/w))))\n",
    "    \n",
    "    new_h, new_w, _ = rs_img.shape\n",
    "    h_start = int((target_size - new_h) / 2)\n",
    "    w_start = int((target_size - new_w) / 2)\n",
    "    \n",
    "    rs_pd_img = np.zeros((target_size, target_size, 3))\n",
    "    rs_pd_img[h_start:h_start+new_h, w_start:w_start+new_w, :] = rs_img\n",
    "    \n",
    "    assert(rs_pd_img.shape == (target_size, target_size, 3))\n",
    "    \n",
    "    return np.uint8(rs_pd_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train Ceil Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "threads = 30"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_mask_dir = '../input/hpa-mask/train/hpa_cell_mask'\n",
    "\n",
    "def extract_train_cell(idx):\n",
    "    image_id = dfs.iloc[idx].ID\n",
    "    labels = dfs.iloc[idx].Label\n",
    "    cell_mask = np.load(f'{cell_mask_dir}/{image_id}.npz')['arr_0']\n",
    "    red = read_img(image_id, \"red\", train_or_test, None)\n",
    "    green = read_img(image_id, \"green\", train_or_test, None)\n",
    "    blue = read_img(image_id, \"blue\", train_or_test, None)\n",
    "    # yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n",
    "    stacked_image = np.transpose(np.array([blue, green, red]), (1,2,0))\n",
    "\n",
    "    for cell in range(1, np.max(cell_mask) + 1):\n",
    "        bmask = cell_mask == cell\n",
    "        cropped_cell = np.uint8(get_cropped_cell(stacked_image, bmask))\n",
    "        \n",
    "        fname = f'{image_id}_{cell}_{labels}.jpg'\n",
    "        rs_pd_cell = resize_and_padding(cropped_cell)\n",
    "        Image.fromarray(rs_pd_cell).save(os.path.join(cell_save_path, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_save_path = '../input/hpa-cell/train/'\n",
    "os.makedirs(cell_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(processes=threads)\n",
    "num_files = len(dfs)\n",
    "pool.map(extract_train_cell, range(num_files));\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Ceil Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_or_test = 'test'\n",
    "cell_mask_dir = '../input/hpa-mask/test/hpa_cell_mask'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_test_cell(image_id):\n",
    "    cell_mask = np.load(f'{cell_mask_dir}/{image_id}.npz')['arr_0']\n",
    "    red = read_img(image_id, \"red\", train_or_test, None)\n",
    "    green = read_img(image_id, \"green\", train_or_test, None)\n",
    "    blue = read_img(image_id, \"blue\", train_or_test, None)\n",
    "    # yellow = read_img(image_id, \"yellow\", train_or_test, image_size)\n",
    "    stacked_image = np.transpose(np.array([blue, green, red]), (1,2,0))\n",
    "\n",
    "    for cell in range(1, np.max(cell_mask) + 1):\n",
    "        bmask = cell_mask == cell\n",
    "        cropped_cell = np.uint8(get_cropped_cell(stacked_image, bmask))\n",
    "        \n",
    "        labels = np.random.randint(0, 19, 1)[0]\n",
    "        \n",
    "        fname = f'{image_id}_{cell}_{labels}.jpg'\n",
    "        rs_pd_cell = resize_and_padding(cropped_cell)\n",
    "        Image.fromarray(rs_pd_cell).save(os.path.join(cell_save_path, fname))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cell_save_path = '../input/hpa-cell/test/'\n",
    "os.makedirs(cell_save_path, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_ids = [item.split('/')[-1].split('.')[0] for item in glob.glob('../input/hpa-mask/test/hpa_cell_mask/*.npz')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pool = Pool(processes=threads)\n",
    "num_files = len(dfs)\n",
    "pool.map(extract_test_cell, image_ids);\n",
    "pool.close()\n",
    "pool.join()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
